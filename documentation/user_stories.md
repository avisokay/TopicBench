# User Stories for TopicBench

## User Story 1: LLM Developer
Sarah is an LLM developer. She is an experienced programmer. She wants to evaluate the performance of her language model on the task of labeling keyword clusters derived from topic modeling. She is capable of implementing a similar tool herself and is using our version for speed and convenience. She wants to quickly assess how her model performs in comparison to other state of the art models. This will help her understand how well her model can interpret and generate meaningful labels for topics in computational social science datasets.

## User Story 2: Computational Social Scientist
As a computational social scientist, I want to use TopicBench to benchmark different LLMs on their ability to label keyword clusters. I can use a Python library that is well documented but I don't know how to call LLMs using an API. This will assist me in selecting the most suitable model for my research projects that involve topic modeling and text analysis. 

## User Story 3: Original Researchers
As one of the original researchers involved in the development of TopicBench, I want to be able to automate the benchmarking process for various LLMs. This will enable me to efficiently compare model performances and publish findings that can guide future research in the field. I also want to make this software accessible to other researchers in computational social science or developers of LLMs, so they can benefit from our work.

## User Story 4: Data Scientist
Jordan is a Data Scientist who is testing different topic modeling algorithms. They want to leverage TopicBench to understand how different LLMs perform in labeling topics from different existing topic modeling algorithms. This will help them identify trade-offs between topic modeling methods and LLM labeling capabilities.

